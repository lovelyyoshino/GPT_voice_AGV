import os.path

from libs.helper import *
import streamlit as st
import uuid
import pandas as pd
import openai
from requests.models import ChunkedEncodingError
from streamlit.components import v1
from voice_toolkit import voice_toolkit
import time

if "apibase" in st.secrets:
    openai.api_base = st.secrets["apibase"]
else:
    os.environ["http_proxy"] = st.secrets["proxies"]
    os.environ["https_proxy"] = st.secrets["proxies"]
    openai.proxy = {"http": st.secrets["proxies"], "https": st.secrets["proxies"]}
    openai.api_base = "https://api.openai.com/v1"
    # openai.proxy = {'http': st.secrets["proxies"], 'https': st.secrets["proxies"]}

st.set_page_config(page_title="ChatGPT Assistant", layout="wide", page_icon="ğŸ¤–")
# è‡ªå®šä¹‰å…ƒç´ æ ·å¼
st.markdown(css_code, unsafe_allow_html=True)

if "initial_settings" not in st.session_state:#åˆå§‹åŒ–è®¾ç½®
    # å†å²èŠå¤©çª—å£
    st.session_state["path"] = "history_chats_file"#èŠå¤©è®°å½•ä¿å­˜è·¯å¾„
    st.session_state["history_chats"] = get_history_chats(st.session_state["path"])#è·å–èŠå¤©è®°å½•
    # sså‚æ•°åˆå§‹åŒ–
    st.session_state["delete_dict"] = {}#åˆ é™¤å­—å…¸
    st.session_state["delete_count"] = 0#åˆ é™¤è®¡æ•°
    st.session_state["voice_flag"] = ""#è¯­éŸ³æ ‡å¿—
    st.session_state["user_voice_value"] = ""#ç”¨æˆ·è¯­éŸ³å€¼
    st.session_state["error_info"] = ""#é”™è¯¯ä¿¡æ¯
    st.session_state["current_chat_index"] = 0#å½“å‰èŠå¤©ç´¢å¼•
    st.session_state["user_input_content"] = ""#ç”¨æˆ·è¾“å…¥å†…å®¹
    # è¯»å–å…¨å±€è®¾ç½®ï¼Œå¦‚æœå­˜åœ¨åˆ™åŠ è½½
    if os.path.exists("./set.json"):
        with open("./set.json", "r", encoding="utf-8") as f:
            data_set = json.load(f)
        for key, value in data_set.items():
            st.session_state[key] = value
    # è®¾ç½®å®Œæˆ
    st.session_state["initial_settings"] = True

with st.sidebar:#ä¾§è¾¹æ 
    side_title="èŠå¤©è®°å½•"
    st.sidebar.markdown(f"\n<div class='avatar'>{gpt_svg}<h1>{side_title}</h1></div>", unsafe_allow_html=True)
    # åˆ›å»ºå®¹å™¨çš„ç›®çš„æ˜¯é…åˆè‡ªå®šä¹‰ç»„ä»¶çš„ç›‘å¬æ“ä½œ
    chat_container = st.container()
    with chat_container:#èŠå¤©å®¹å™¨
        current_chat = st.radio(
            label="å†å²èŠå¤©çª—å£",
            format_func=lambda x: x.split("_")[0] if "_" in x else x,
            options=st.session_state["history_chats"],
            label_visibility="collapsed",
            index=st.session_state["current_chat_index"],
            key="current_chat"
            + st.session_state["history_chats"][st.session_state["current_chat_index"]],
            # on_change=current_chat_callback  # æ­¤å¤„ä¸é€‚åˆç”¨å›è°ƒï¼Œæ— æ³•è¯†åˆ«åˆ°çª—å£å¢å‡çš„å˜åŠ¨
        )#åˆ›å»ºä¸€ä¸ªå•é€‰æ¡†ï¼Œç”¨äºé€‰æ‹©èŠå¤©çª—å£
    st.write("---")


# æ•°æ®å†™å…¥æ–‡ä»¶
def write_data(new_chat_name=current_chat):
    if "apikey" in st.secrets:
        st.session_state["paras"] = {
            "temperature": st.session_state["temperature" + current_chat],
            "top_p": st.session_state["top_p" + current_chat],
            "presence_penalty": st.session_state["presence_penalty" + current_chat],
            "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
        }#å°†å‚æ•°ä¿å­˜åˆ°parasä¸­
        st.session_state["contexts"] = {
            "context_select": st.session_state["context_select" + current_chat],
            "context_input": st.session_state["context_input" + current_chat],
            "context_level": st.session_state["context_level" + current_chat],
        }#å°†ä¸Šä¸‹æ–‡ä¿å­˜åˆ°contextsä¸­
        save_data(
            st.session_state["path"],
            new_chat_name,
            st.session_state["history" + current_chat],
            st.session_state["paras"],
            st.session_state["contexts"],
        )#ä¿å­˜æ•°æ®

# é‡å‘½åæ–‡ä»¶
def reset_chat_name_fun(chat_name):
    chat_name = chat_name + "_" + str(uuid.uuid4())#ç»™èŠå¤©çª—å£å‘½å
    new_name = filename_correction(chat_name)#æ–‡ä»¶åçº æ­£
    current_chat_index = st.session_state["history_chats"].index(current_chat)#è·å–å½“å‰èŠå¤©ç´¢å¼•
    st.session_state["history_chats"][current_chat_index] = new_name#å°†æ–°çš„èŠå¤©çª—å£åå­—èµ‹å€¼ç»™å½“å‰èŠå¤©ç´¢å¼•
    st.session_state["current_chat_index"] = current_chat_index#å°†å½“å‰èŠå¤©ç´¢å¼•èµ‹å€¼ç»™å½“å‰èŠå¤©ç´¢å¼•
    # å†™å…¥æ–°æ–‡ä»¶
    write_data(new_name)
    # è½¬ç§»æ•°æ®
    st.session_state["history" + new_name] = st.session_state["history" + current_chat]
    for item in [
        "context_select",
        "context_input",
        "context_level",
        *initial_content_all["paras"],
    ]:#éå†å‚æ•°
        st.session_state[item + new_name + "value"] = st.session_state[
            item + current_chat + "value"
        ]
    remove_data(st.session_state["path"], current_chat)#åˆ é™¤å½“å‰èŠå¤©çª—å£

# åˆ›å»ºæ–°çš„èŠå¤©çª—å£
def create_chat_fun():
    st.session_state["history_chats"] = [
        "New Chat_" + str(uuid.uuid4())
    ] + st.session_state["history_chats"]#åˆ›å»ºä¸€ä¸ªæ–°çš„èŠå¤©çª—å£
    st.session_state["current_chat_index"] = 0

# åˆ é™¤èŠå¤©çª—å£
def delete_chat_fun():
    if len(st.session_state["history_chats"]) == 1:
        chat_init = "New Chat_" + str(uuid.uuid4())#è®¾ç½®åˆå§‹èŠå¤©çª—å£
        st.session_state["history_chats"].append(chat_init)#å°†åˆå§‹èŠå¤©çª—å£æ·»åŠ åˆ°èŠå¤©çª—å£åˆ—è¡¨ä¸­
    pre_chat_index = st.session_state["history_chats"].index(current_chat)#è·å–å½“å‰èŠå¤©ç´¢å¼•
    if pre_chat_index > 0:
        st.session_state["current_chat_index"] = (
            st.session_state["history_chats"].index(current_chat) - 1
        )#å°†å½“å‰èŠå¤©ç´¢å¼•èµ‹å€¼ç»™å½“å‰èŠå¤©ç´¢å¼•
    else:
        st.session_state["current_chat_index"] = 0
    st.session_state["history_chats"].remove(current_chat)
    remove_data(st.session_state["path"], current_chat)#åˆ é™¤å½“å‰èŠå¤©çª—å£

# ä¿å­˜è®¾ç½®
def save_set(arg):
    st.session_state[arg + "_value"] = st.session_state[arg]
    if "apikey" in st.secrets:
        with open("./set.json", "w", encoding="utf-8") as f:
            json.dump(
                {
                    "open_text_toolkit_value": st.session_state["open_text_toolkit"],
                    "open_voice_toolkit_value": st.session_state["open_voice_toolkit"],
                    "hand_free_toolkit_value": st.session_state["hand_free_toolkit"],
                },
                f,
            )#å°†è®¾ç½®ä¿å­˜åˆ°set.jsonæ–‡ä»¶ä¸­


with st.sidebar:#ä¾§è¾¹æ 
    c1, c2 = st.columns(2)
    create_chat_button = c1.button(
        "æ–°å»º", use_container_width=True, key="create_chat_button"
    )#åˆ›å»ºä¸€ä¸ªæ–°å»ºæŒ‰é’®
    if create_chat_button:
        create_chat_fun()#è°ƒç”¨åˆ›å»ºæ–°çš„èŠå¤©çª—å£å‡½æ•°
        st.rerun()#é‡æ–°æ¸²æŸ“é¡µé¢

    delete_chat_button = c2.button(
        "åˆ é™¤", use_container_width=True, key="delete_chat_button"
    )
    if delete_chat_button:
        delete_chat_fun()#è°ƒç”¨åˆ é™¤èŠå¤©çª—å£å‡½æ•°
        st.rerun()

with st.sidebar:#ä¾§è¾¹æ 
    if ("set_chat_name" in st.session_state) and st.session_state[
        "set_chat_name"
    ] != "":#å¦‚æœset_chat_nameåœ¨ssä¸­ä¸”ä¸ä¸ºç©º
        reset_chat_name_fun(st.session_state["set_chat_name"])#è°ƒç”¨é‡å‘½åæ–‡ä»¶å‡½æ•°
        st.session_state["set_chat_name"] = ""#å°†set_chat_nameèµ‹å€¼ä¸ºç©º
        st.rerun()#é‡æ–°æ¸²æŸ“é¡µé¢

    st.write("\n")
    st.write("\n")
    st.text_input("è®¾å®šçª—å£åç§°ï¼š", key="set_chat_name", placeholder="ç‚¹å‡»è¾“å…¥")
    st.selectbox(
        "é€‰æ‹©æ¨¡å‹ï¼š", index=0, options=["gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","gpt-3.5-turbo", "gpt-3.5-turbo-16k", "gpt-3.5-turbo-0613", "gpt-3.5-turbo-16k-0613",
               "gpt-4", "gpt-4-0613", "gpt-4-32k", "gpt-4-32k-0613", "gpt-3.5-turbo-1106"], key="select_model"
    )#åˆ›å»ºä¸€ä¸ªé€‰æ‹©æ¡†ï¼Œç”¨äºé€‰æ‹©æ¨¡å‹
    st.write("\n")
    st.caption(
        """
    - åŒå‡»é¡µé¢ç›´æ¥å®šä½è¾“å…¥æ 
    - Ctrl + Enter å¿«æ·æäº¤é—®é¢˜
    - å¦‚æœé€‰æ‹©ä½¿ç”¨hand freeæ¨¡å¼ï¼Œå¯ä»¥ç›´æ¥è¯´è¯ï¼Œåœæ­¢è¯´è¯åä¼šè‡ªåŠ¨æäº¤
    """
    )#åˆ›å»ºä¸€ä¸ªæ ‡é¢˜ï¼Œç”¨äºæç¤ºä¿¡æ¯
    st.write("\n")
    if "apikey_input" in st.secrets:
        dbapi_key = st.session_state["apikey_input"]
    # é…ç½®ä¸´æ—¶apikeyï¼Œæ­¤æ—¶ä¸ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œé€‚åˆå…¬å¼€ä½¿ç”¨
    elif "apikey_tem" in st.secrets:
        dbapi_key = st.secrets["apikey_tem"]
    # æ³¨ï¼šå½“st.secretsä¸­é…ç½®apikeyåå°†ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œå³ä½¿æœªä½¿ç”¨æ­¤apikey
    else:
        dbapi_key = st.secrets["apikey"]
    #æ”¯æŒä¸Šä¼ pdf,doc,docx,txt,mdæ–‡ä»¶
    all_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["pdf", "doc", "docx", "txt", "md"], accept_multiple_files=True)
    
    if all_files is not None:  # Process PDF files if uploaded
        multiple_pdfFiles_to_text(all_files,dbapi_key)

    if "hand_free_toolkit_value" in st.session_state:#å¦‚æœhand_free_toolkit_valueåœ¨ssä¸­ï¼Œè¿™ä¸ªæ˜¯ç”¨äºåˆ¤æ–­æ˜¯å¦å¼€å¯è‡ªåŠ¨è¯­éŸ³è¾“å…¥ã€‚é»˜è®¤æ˜¯false
        default = st.session_state["hand_free_toolkit_value"]
    else:
        default = False
    st.checkbox(
        "å¼€å¯è‡ªåŠ¨è¯­éŸ³è¾“å…¥(éœ€è¦åœ¨æ¯”è¾ƒå®‰é™çš„ç¯å¢ƒä¸‹ä½¿ç”¨)",
        value=default,
        key="hand_free_toolkit",
        on_change=save_set,
        args=("hand_free_toolkit",),
    )#åˆ›å»ºä¸€ä¸ªå¤é€‰æ¡†ï¼Œç”¨äºé€‰æ‹©æ˜¯å¦å¼€å¯è‡ªåŠ¨è¯­éŸ³è¾“å…¥

# åŠ è½½æ•°æ®
if "history" + current_chat not in st.session_state:
    for key, value in load_data(st.session_state["path"], current_chat).items():#éå†åŠ è½½æ•°æ®
        if key == "history":
            st.session_state[key + current_chat] = value#å°†valueèµ‹å€¼ç»™ssä¸­çš„key+current_chat
        else:
            for k, v in value.items():
                st.session_state[k + current_chat + "value"] = v#å°†vèµ‹å€¼ç»™ssä¸­çš„k+current_chat+value

# ä¿è¯ä¸åŒchatçš„é¡µé¢å±‚æ¬¡ä¸€è‡´ï¼Œå¦åˆ™ä¼šå¯¼è‡´è‡ªå®šä¹‰ç»„ä»¶é‡æ–°æ¸²æŸ“
container_show_messages = st.container()#åˆ›å»ºä¸€ä¸ªå®¹å™¨
container_show_messages.write("")
# å¯¹è¯å±•ç¤º
with container_show_messages:
    if st.session_state["history" + current_chat]:#å¦‚æœhistory+current_chatåœ¨ssä¸­
        show_messages(current_chat, st.session_state["history" + current_chat])#å±•ç¤ºæ¶ˆæ¯

# æ ¸æŸ¥æ˜¯å¦æœ‰å¯¹è¯éœ€è¦åˆ é™¤
if any(st.session_state["delete_dict"].values()):
    for key, value in st.session_state["delete_dict"].items():#éå†åˆ é™¤å­—å…¸
        try:
            deleteCount = value.get("deleteCount")
        except AttributeError:
            deleteCount = None
        if deleteCount == st.session_state["delete_count"]:#å¦‚æœdeleteCountç­‰äºssä¸­çš„delete_count
            delete_keys = key
            st.session_state["delete_count"] = deleteCount + 1
            delete_current_chat, idr = delete_keys.split(">")
            df_history_tem = pd.DataFrame(
                st.session_state["history" + delete_current_chat]
            )#å°†ssä¸­çš„history+delete_current_chatè½¬æ¢ä¸ºDataFrame
            df_history_tem.drop(
                index=df_history_tem.query("role=='user'").iloc[[int(idr)], :].index,
                inplace=True,
            )#åˆ é™¤ç”¨æˆ·
            df_history_tem.drop(
                index=df_history_tem.query("role=='assistant'")
                .iloc[[int(idr)], :]
                .index,
                inplace=True,
            )#åˆ é™¤åŠ©æ‰‹
            st.session_state["history" + delete_current_chat] = df_history_tem.to_dict(
                "records"
            )#å°†df_history_temè½¬æ¢ä¸ºå­—å…¸
            write_data()#å†™å…¥æ•°æ®
            st.rerun()

# ä¿å­˜è®¾ç½®
def callback_fun(arg):
    # è¿ç»­å¿«é€Ÿç‚¹å‡»æ–°å»ºä¸åˆ é™¤ä¼šè§¦å‘é”™è¯¯å›è°ƒï¼Œå¢åŠ åˆ¤æ–­
    if ("history" + current_chat in st.session_state) and (
        "frequency_penalty" + current_chat in st.session_state
    ):
        write_data()
        st.session_state[arg + current_chat + "value"] = st.session_state[
            arg + current_chat
        ]

# æ¸…ç©ºèŠå¤©è®°å½•
def clear_button_callback():
    st.session_state["history" + current_chat] = []
    write_data()

# åˆ é™¤æ‰€æœ‰çª—å£
def delete_all_chat_button_callback():
    if "apikey" in st.secrets:
        folder_path = st.session_state["path"]
        file_list = os.listdir(folder_path)
        for file_name in file_list:
            file_path = os.path.join(folder_path, file_name)
            if file_name.endswith(".json") and os.path.isfile(file_path):
                os.remove(file_path)
    st.session_state["current_chat_index"] = 0
    st.session_state["history_chats"] = ["New Chat_" + str(uuid.uuid4())]



# è¾“å…¥å†…å®¹å±•ç¤º
area_user_svg = st.empty()
area_user_content = st.empty()
# å›å¤å±•ç¤º
area_gpt_svg = st.empty()
area_gpt_content = st.empty()
# æŠ¥é”™å±•ç¤º
area_error = st.empty()

st.write("\n")
st.header("SHINE AGV Assistant")
tap_input, tap_context, tap_model, tab_func = st.tabs(
    ["ğŸ’¬ èŠå¤©", "ğŸ—’ï¸ é¢„è®¾", "âš™ï¸ æ¨¡å‹", "ğŸ› ï¸ åŠŸèƒ½"]
)#åˆ›å»ºä¸€ä¸ªæ ‡ç­¾é¡µ

# é¢„è®¾çª—å£ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡å’Œæ¨¡å‹å‚æ•°
with tap_context:
    set_context_list = list(set_context_all.keys())
    context_select_index = set_context_list.index(
        st.session_state["context_select" + current_chat + "value"]
    )#è·å–ä¸Šä¸‹æ–‡ç´¢å¼•ï¼Œè¿™é‡Œst.session_state["context_select" + current_chat + "value"]æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²,åœ¨set_context_listä¸­æ‰¾åˆ°è¿™ä¸ªå­—ç¬¦ä¸²çš„ç´¢å¼•
    st.selectbox(
        label="é€‰æ‹©ä¸Šä¸‹æ–‡",
        options=set_context_list,
        key="context_select" + current_chat,
        index=context_select_index,
        on_change=callback_fun,
        args=("context_select",),
    )#åˆ›å»ºä¸€ä¸ªé€‰æ‹©æ¡†ï¼Œç”¨äºé€‰æ‹©ä¸Šä¸‹æ–‡
    st.caption(set_context_all[st.session_state["context_select" + current_chat]])#åˆ›å»ºä¸€ä¸ªæ ‡é¢˜ï¼Œç”¨äºå±•ç¤ºä¸Šä¸‹æ–‡çš„å†…å®¹

    st.text_area(
        label="è¡¥å……æˆ–è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ï¼š",
        key="context_input" + current_chat,
        value=st.session_state["context_input" + current_chat + "value"],
        on_change=callback_fun,
        args=("context_input",),
    )#åˆ›å»ºä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†ï¼Œç”¨äºè¾“å…¥ä¸Šä¸‹æ–‡

# æ¨¡å‹å‚æ•°
with tap_model:
    st.markdown("OpenAI API Key (å¯é€‰)")
    st.text_input(
        "OpenAI API Key (å¯é€‰)",
        type="password",
        key="apikey_input",
        label_visibility="collapsed",
    )#åˆ›å»ºä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†ï¼Œç”¨äºè¾“å…¥OpenAI API Key
    st.caption(
        "æ­¤Keyä»…åœ¨å½“å‰ç½‘é¡µæœ‰æ•ˆï¼Œä¸”ä¼˜å…ˆçº§é«˜äºSecretsä¸­çš„é…ç½®ï¼Œä»…è‡ªå·±å¯ç”¨ï¼Œä»–äººæ— æ³•å…±äº«ã€‚[å®˜ç½‘è·å–](https://platform.openai.com/account/api-keys)"
    )

    st.markdown("åŒ…å«å¯¹è¯æ¬¡æ•°ï¼š")
    st.slider(
        "Context Level",
        0,
        10,
        st.session_state["context_level" + current_chat + "value"],
        1,
        on_change=callback_fun,
        key="context_level" + current_chat,
        args=("context_level",),
        help="è¡¨ç¤ºæ¯æ¬¡ä¼šè¯ä¸­åŒ…å«çš„å†å²å¯¹è¯æ¬¡æ•°ï¼Œé¢„è®¾å†…å®¹ä¸è®¡ç®—åœ¨å†…ã€‚",
    )#åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©åŒ…å«å¯¹è¯æ¬¡æ•°

    st.markdown("æ¨¡å‹å‚æ•°ï¼š")
    st.slider(
        "Temperature",
        0.0,
        2.0,
        st.session_state["temperature" + current_chat + "value"],
        0.1,
        help="""åœ¨0å’Œ2ä¹‹é—´ï¼Œåº”è¯¥ä½¿ç”¨ä»€ä¹ˆæ ·çš„é‡‡æ ·æ¸©åº¦ï¼Ÿè¾ƒé«˜çš„å€¼ï¼ˆå¦‚0.8ï¼‰ä¼šä½¿è¾“å‡ºæ›´éšæœºï¼Œè€Œè¾ƒä½çš„å€¼ï¼ˆå¦‚0.2ï¼‰åˆ™ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®šæ€§ã€‚
          æˆ‘ä»¬ä¸€èˆ¬å»ºè®®åªæ›´æ”¹è¿™ä¸ªå‚æ•°æˆ–top_på‚æ•°ä¸­çš„ä¸€ä¸ªï¼Œè€Œä¸è¦åŒæ—¶æ›´æ”¹ä¸¤ä¸ªã€‚""",
        on_change=callback_fun,
        key="temperature" + current_chat,
        args=("temperature",),
    )#åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©æ¸©åº¦
    st.slider(
        "Top P",
        0.1,
        1.0,
        st.session_state["top_p" + current_chat + "value"],
        0.1,
        help="""ä¸€ç§æ›¿ä»£é‡‡ç”¨æ¸©åº¦è¿›è¡Œé‡‡æ ·çš„æ–¹æ³•ï¼Œç§°ä¸ºâ€œåŸºäºæ ¸å¿ƒæ¦‚ç‡â€çš„é‡‡æ ·ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œæ¨¡å‹ä¼šè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„top_pä¸ªæ ‡è®°çš„é¢„æµ‹ç»“æœã€‚
          å› æ­¤ï¼Œå½“è¯¥å‚æ•°ä¸º0.1æ—¶ï¼Œåªæœ‰åŒ…æ‹¬å‰10%æ¦‚ç‡è´¨é‡çš„æ ‡è®°å°†è¢«è€ƒè™‘ã€‚æˆ‘ä»¬ä¸€èˆ¬å»ºè®®åªæ›´æ”¹è¿™ä¸ªå‚æ•°æˆ–é‡‡æ ·æ¸©åº¦å‚æ•°ä¸­çš„ä¸€ä¸ªï¼Œè€Œä¸è¦åŒæ—¶æ›´æ”¹ä¸¤ä¸ªã€‚""",
        on_change=callback_fun,
        key="top_p" + current_chat,
        args=("top_p",),
    )#åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©top_p
    st.slider(
        "Presence Penalty",
        -2.0,
        2.0,
        st.session_state["presence_penalty" + current_chat + "value"],
        0.1,
        help="""è¯¥å‚æ•°çš„å–å€¼èŒƒå›´ä¸º-2.0åˆ°2.0ã€‚æ­£å€¼ä¼šæ ¹æ®æ–°æ ‡è®°æ˜¯å¦å‡ºç°åœ¨å½“å‰ç”Ÿæˆçš„æ–‡æœ¬ä¸­å¯¹å…¶è¿›è¡Œæƒ©ç½šï¼Œä»è€Œå¢åŠ æ¨¡å‹è°ˆè®ºæ–°è¯é¢˜çš„å¯èƒ½æ€§ã€‚""",
        on_change=callback_fun,
        key="presence_penalty" + current_chat,
        args=("presence_penalty",),
    )#åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©presence_penalty
    st.slider(
        "Frequency Penalty",
        -2.0,
        2.0,
        st.session_state["frequency_penalty" + current_chat + "value"],
        0.1,
        help="""è¯¥å‚æ•°çš„å–å€¼èŒƒå›´ä¸º-2.0åˆ°2.0ã€‚æ­£å€¼ä¼šæ ¹æ®æ–°æ ‡è®°åœ¨å½“å‰ç”Ÿæˆçš„æ–‡æœ¬ä¸­çš„å·²æœ‰é¢‘ç‡å¯¹å…¶è¿›è¡Œæƒ©ç½šï¼Œä»è€Œå‡å°‘æ¨¡å‹ç›´æ¥é‡å¤ç›¸åŒè¯­å¥çš„å¯èƒ½æ€§ã€‚""",
        on_change=callback_fun,
        key="frequency_penalty" + current_chat,
        args=("frequency_penalty",),
    )#åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºé€‰æ‹©frequency_penalty
    st.caption(
        "[å®˜ç½‘å‚æ•°è¯´æ˜](https://platform.openai.com/docs/api-reference/completions/create)"
    )

# åŠŸèƒ½ç»„ä»¶
with tab_func:
    c1, c2, c3 = st.columns(3)
    with c1:
        st.button("æ¸…ç©ºèŠå¤©è®°å½•", use_container_width=True, on_click=clear_button_callback)
    with c2:
        btn = st.download_button(
            label="å¯¼å‡ºèŠå¤©è®°å½•",
            data=download_history(st.session_state["history" + current_chat]),
            file_name=f'{current_chat.split("_")[0]}.md',
            mime="text/markdown",
            use_container_width=True,
        )
    with c3:
        st.button(
            "åˆ é™¤æ‰€æœ‰çª—å£", use_container_width=True, on_click=delete_all_chat_button_callback
        )

    st.write("\n")
    st.markdown("è‡ªå®šä¹‰åŠŸèƒ½ï¼š")
    c1, c2 = st.columns(2)#è‡ªå®šä¹‰åŠŸèƒ½ï¼Œåˆ›å»ºä¸¤ä¸ªæŒ‰é’®
    with c1:#ç¬¬ä¸€ä¸ªæŒ‰é’®é»˜è®¤ä¸º
        if "open_text_toolkit_value" in st.session_state:
            default = st.session_state["open_text_toolkit_value"]#å¦‚æœopen_text_toolkit_valueåœ¨ssä¸­
        else:
            default = True#å¦åˆ™é»˜è®¤ä¸ºTrue
        st.checkbox(
            "å¼€å¯æ–‡æœ¬ä¸‹çš„åŠŸèƒ½ç»„ä»¶",
            value=default,
            key="open_text_toolkit",
            on_change=save_set,
            args=("open_text_toolkit",),
        )#åˆ›å»ºä¸€ä¸ªå¤é€‰æ¡†ï¼Œå°†å€¼ä¿å­˜åˆ°ssä¸­
    with c2:
        if "open_voice_toolkit_value" in st.session_state:
            default = st.session_state["open_voice_toolkit_value"]
        else:
            default = True
        st.checkbox(
            "å¼€å¯è¯­éŸ³è¾“å…¥ç»„ä»¶",
            value=default,
            key="open_voice_toolkit",
            on_change=save_set,
            args=("open_voice_toolkit",),
        )

# è¾“å…¥æ¡†
with tap_input:

    def input_callback():#è¾“å…¥å›è°ƒ
        if st.session_state["user_input_area"] != "":
            # ä¿®æ”¹çª—å£åç§°
            user_input_content = st.session_state["user_input_area"]
            df_history = pd.DataFrame(st.session_state["history" + current_chat])
            if df_history.empty or len(df_history.query('role!="system"')) == 0:
                new_name = extract_chars(user_input_content, 18)
                reset_chat_name_fun(new_name)

    with st.form("input_form", clear_on_submit=True):#åˆ›å»ºä¸€ä¸ªè¡¨å•
        user_input = st.text_area(
            "**è¾“å…¥ï¼š**",
            key="user_input_area",
            help="å†…å®¹å°†ä»¥Markdownæ ¼å¼åœ¨é¡µé¢å±•ç¤ºï¼Œå»ºè®®éµå¾ªç›¸å…³è¯­è¨€è§„èŒƒï¼ŒåŒæ ·æœ‰åˆ©äºGPTæ­£ç¡®è¯»å–ï¼Œä¾‹å¦‚ï¼š"
            "\n- ä»£ç å—å†™åœ¨ä¸‰ä¸ªåå¼•å·å†…ï¼Œå¹¶æ ‡æ³¨è¯­è¨€ç±»å‹"
            "\n- ä»¥è‹±æ–‡å†’å·å¼€å¤´çš„å†…å®¹æˆ–è€…æ­£åˆ™è¡¨è¾¾å¼ç­‰å†™åœ¨å•åå¼•å·å†…",
            value=st.session_state["user_voice_value"],
        )#åˆ›å»ºä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†ï¼Œç”¨äºè¾“å…¥å†…å®¹
        submitted = st.form_submit_button(
            "ç¡®è®¤æäº¤", use_container_width=True, on_click=input_callback
        )#åˆ›å»ºä¸€ä¸ªæäº¤æŒ‰é’®
    if submitted:
        st.session_state["user_input_content"] = user_input#å°†user_inputèµ‹å€¼ç»™ssä¸­çš„user_input_content
        st.session_state["user_voice_value"] = ""
        st.rerun()

    if (
        "open_voice_toolkit_value" not in st.session_state
        or st.session_state["open_voice_toolkit_value"] 
        or "hand_free_toolkit_value" not in st.session_state
        or st.session_state["hand_free_toolkit_value"]
    ):  # å¦‚æœæ²¡æœ‰è¢«ç‚¹å‡»è¿‡æˆ–è€…è¢«ç‚¹å‡»è¿‡ä¸”å€¼ä¸ºTrue
        # è¯­éŸ³è¾“å…¥åŠŸèƒ½
        # voice_result = voice_toolkit()
        # è°ƒç”¨è‡ªå®šä¹‰ç»„ä»¶ï¼Œå¹¶ä¼ é€’å½•éŸ³çŠ¶æ€
        if "hand_free_toolkit_value" not in st.session_state:
            voice_result = False
        else:
            print("hand_free_toolkit_value:",st.session_state["hand_free_toolkit_value"])
            voice_result = voice_toolkit(is_recording=st.session_state["hand_free_toolkit_value"])
        # voice_resultä¼šä¿å­˜æœ€åä¸€æ¬¡ç»“æœ
        if (
            voice_result and voice_result["voice_result"]["flag"] == "interim"
        ) or st.session_state["voice_flag"] == "interim":#å¦‚æœvoice_resultä¸ä¸ºç©ºä¸”voice_resultçš„flagä¸ºinterim
            st.session_state["voice_flag"] = "interim"
            st.session_state["user_voice_value"] = voice_result["voice_result"]["value"]
            print("user_voice_value:",st.session_state["user_voice_value"])
            if voice_result["voice_result"]["flag"] == "final":#å¦‚æœvoice_resultçš„flagä¸ºfinal
                st.session_state["voice_flag"] = "final"
                # æ£€æŸ¥æ˜¯å¦å¼€å¯äº†hand freeæ¨¡å¼
                if st.session_state["hand_free_toolkit_value"]:
                    time.sleep(1)
                    input_callback()  # æ‰‹åŠ¨è°ƒç”¨å¤„ç†å‡½æ•°
                    st.session_state["user_input_content"] = st.session_state["user_voice_value"]
                    st.session_state["user_voice_value"] = ""  # æ¸…é™¤è¯­éŸ³è¾“å…¥å€¼
                    st.rerun()  # é‡æ–°æ¸²æŸ“é¡µé¢
                else:
                    st.rerun()  # å¦‚æœä¸åœ¨hand freeæ¨¡å¼ä¸‹ï¼Œä»ç„¶éœ€è¦é‡æ–°æ¸²æŸ“ä»¥æ›´æ–°çŠ¶æ€

# è·å–æ¨¡å‹è¾“å…¥
def get_model_input():
    # éœ€è¾“å…¥çš„å†å²è®°å½•
    context_level = st.session_state["context_level" + current_chat]
    history = get_history_input(
        st.session_state["history" + current_chat], context_level
    ) + [{"role": "user", "content": st.session_state["pre_user_input_content"]}]#è·å–å†å²è®°å½•
    for ctx in [
        st.session_state["context_input" + current_chat],
        set_context_all[st.session_state["context_select" + current_chat]],
    ]:#éå†ä¸Šä¸‹æ–‡
        if ctx != "":
            history = [{"role": "system", "content": ctx}] + history
    # è®¾å®šçš„æ¨¡å‹å‚æ•°
    paras = {
        "temperature": st.session_state["temperature" + current_chat],
        "top_p": st.session_state["top_p" + current_chat],
        "presence_penalty": st.session_state["presence_penalty" + current_chat],
        "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
    }
    return history, paras


# è·å–æ¨¡å‹è¾“å…¥
def get_twice_model_input(idx_content):
    # éœ€è¾“å…¥çš„å†å²è®°å½•
    context_level = st.session_state["context_level" + current_chat]
    history = get_history_input(
        st.session_state["history" + current_chat], context_level
    ) + [{"role": "user", "content": st.session_state["pre_user_input_content"]}]#è·å–å†å²è®°å½•
    for ctx in [
        st.session_state["context_input" + current_chat],
        set_context_all[idx_content],
    ]:#éå†ä¸Šä¸‹æ–‡
        if ctx != "":
            history = [{"role": "system", "content": ctx}] + history
    # è®¾å®šçš„æ¨¡å‹å‚æ•°
    paras = {
        "temperature": st.session_state["temperature" + current_chat],
        "top_p": st.session_state["top_p" + current_chat],
        "presence_penalty": st.session_state["presence_penalty" + current_chat],
        "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
    }
    return history, paras


if st.session_state["user_input_content"] != "":#å¦‚æœuser_input_contentä¸ä¸ºç©º,åˆ™è®¤ä¸ºç”¨æˆ·å·²ç»è¾“å…¥
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.session_state[current_chat + "report"] = ""
    st.session_state["pre_user_input_content"] = st.session_state["user_input_content"]
    st.session_state["user_input_content"] = ""
    # ä¸´æ—¶å±•ç¤º
    show_each_message(
        st.session_state["pre_user_input_content"],
        "user",
        "tem",
        [area_user_svg.markdown, area_user_content.markdown],
    )
    # æ¨¡å‹è¾“å…¥
    history_need_input, paras_need_input = get_model_input()
    # è°ƒç”¨æ¥å£
    with st.spinner("ğŸ¤”"):
        try:
            if apikey := st.session_state["apikey_input"]:
                openai.api_key = apikey
            # é…ç½®ä¸´æ—¶apikeyï¼Œæ­¤æ—¶ä¸ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œé€‚åˆå…¬å¼€ä½¿ç”¨
            elif "apikey_tem" in st.secrets:
                openai.api_key = st.secrets["apikey_tem"]
            # æ³¨ï¼šå½“st.secretsä¸­é…ç½®apikeyåå°†ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œå³ä½¿æœªä½¿ç”¨æ­¤apikey
            else:
                openai.api_key = st.secrets["apikey"]
            
            set_context_list = list(set_context_all.keys())
            context_select_index = set_context_list.index(
                        st.session_state["context_select" + current_chat + "value"])
            
            num =0
            if context_select_index == 0:# ä»£è¡¨æ˜¯éœ€è¦ä»å¤´å¼€å§‹ç†è§£
                while num > 13 or num < 1:
                    r = openai.ChatCompletion.create(
                        model=st.session_state["select_model"],
                        messages=history_need_input,
                        stream=True,
                        **paras_need_input,
                    )
                    respone_msg = ""
                    for e in r:
                        if "content" in e["choices"][0]["delta"]:
                            respone_msg += e["choices"][0]["delta"]["content"]
                    #æ‰¾åˆ°å›å¤ä¸­çš„æ•°å­—ï¼ŒèŒƒå›´ä¸º1-13
                    num = re.findall(r"\d+", respone_msg)
                    if len(num) > 0:
                        num = int(num[0])
                        if num > 0 and num < 14:
                            index_contect = set_context_list[num]
                            history_need_input, paras_need_input = get_twice_model_input(index_contect)
                            break
                    else:
                        num = 0
            # print("context_select_index:",context_select_index)
            if context_select_index > 13:#è¿™ä¸ªä»£è¡¨ä¸åœ¨æŒ‡ä»¤é›†é‡Œé¢ï¼Œéœ€è¦å€ŸåŠ©chromaDBå›ç­”é—®é¢˜
                if apikey := st.session_state["apikey_input"]:
                    dbapi_key = apikey
                # é…ç½®ä¸´æ—¶apikeyï¼Œæ­¤æ—¶ä¸ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œé€‚åˆå…¬å¼€ä½¿ç”¨
                elif "apikey_tem" in st.secrets:
                    dbapi_key = st.secrets["apikey_tem"]
                # æ³¨ï¼šå½“st.secretsä¸­é…ç½®apikeyåå°†ä¼šç•™å­˜èŠå¤©è®°å½•ï¼Œå³ä½¿æœªä½¿ç”¨æ­¤apikey
                else:
                    dbapi_key = st.secrets["apikey"]

                # print("api_key:",dbapi_key,st.session_state["pre_user_input_content"],history_need_input,paras_need_input)
                res = user_query_response(st.session_state["pre_user_input_content"],history_need_input,dbapi_key,st.session_state["select_model"],set_context_all[st.session_state["context_select" + current_chat]])
                # transform the response to the format of GPT
                r = []
                r.append({"choices": [{"delta": {"content": res}}]})
            else:
                r = openai.ChatCompletion.create(
                    model=st.session_state["select_model"],
                    messages=history_need_input,
                    stream=True,
                    **paras_need_input,
                )
        except (FileNotFoundError, KeyError):
            area_error.error(
                "ç¼ºå¤± OpenAI API Keyï¼Œè¯·åœ¨å¤åˆ¶é¡¹ç›®åé…ç½®Secretsï¼Œæˆ–è€…åœ¨æ¨¡å‹é€‰é¡¹ä¸­è¿›è¡Œä¸´æ—¶é…ç½®ã€‚"
                "è¯¦æƒ…è§[é¡¹ç›®ä»“åº“](https://github.com/PierXuY/ChatGPT-Assistant)ã€‚"
            )
        except openai.error.AuthenticationError:
            area_error.error("æ— æ•ˆçš„ OpenAI API Keyã€‚")
        except openai.error.APIConnectionError as e:
            area_error.error("è¿æ¥è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        except openai.error.InvalidRequestError as e:
            area_error.error("æ— æ•ˆçš„è¯·æ±‚ï¼Œè¯·é‡è¯•ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        except openai.error.RateLimitError as e:
            area_error.error("è¯·æ±‚å—é™ã€‚æŠ¥é”™ï¼š   \n" + str(e.args[0]))
        else:
            st.session_state["chat_of_r"] = current_chat
            st.session_state["r"] = r
            st.rerun()

if ("r" in st.session_state) and (current_chat == st.session_state["chat_of_r"]):#å¦‚æœråœ¨ssä¸­ä¸”å½“å‰èŠå¤©ç­‰äºssä¸­çš„chat_of_r
    if current_chat + "report" not in st.session_state:#å¦‚æœcurrent_chat+reportä¸åœ¨ssä¸­
        st.session_state[current_chat + "report"] = ""
    try:
        for e in st.session_state["r"]:
            if "content" in e["choices"][0]["delta"]:
                st.session_state[current_chat + "report"] += e["choices"][0]["delta"][
                    "content"
                ]
                show_each_message(
                    st.session_state["pre_user_input_content"],
                    "user",
                    "tem",
                    [area_user_svg.markdown, area_user_content.markdown],
                )#å±•ç¤ºæ¶ˆæ¯
                show_each_message(
                    st.session_state[current_chat + "report"],
                    "assistant",
                    "tem",
                    [area_gpt_svg.markdown, area_gpt_content.markdown],
                )
    except ChunkedEncodingError:
        area_error.error("ç½‘ç»œçŠ¶å†µä¸ä½³ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚")
    # åº”å¯¹stopæƒ…å½¢
    except Exception:
        pass
    else:
        # ä¿å­˜å†…å®¹
        st.session_state["history" + current_chat].append(
            {"role": "user", "content": st.session_state["pre_user_input_content"]}
        )
        st.session_state["history" + current_chat].append(
            {"role": "assistant", "content": st.session_state[current_chat + "report"]}
        )
        write_data()
    # ç”¨æˆ·åœ¨ç½‘é¡µç‚¹å‡»stopæ—¶ï¼ŒssæŸäº›æƒ…å½¢ä¸‹ä¼šæš‚æ—¶ä¸ºç©º
    if current_chat + "report" in st.session_state:
        st.session_state.pop(current_chat + "report")
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.rerun()

# æ·»åŠ äº‹ä»¶ç›‘å¬
v1.html(js_code, height=0)
